---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

# 🤝LIR Lab Introduction
Our team consists of 3 PhD candidates and 25 master's students.

**Core Focus:**  
We concentrate on the field of computer vision, with key areas of research including:
- **⚙️ Low-level Vision Enhancement:** Low light, adverse weather adaptation, denoising, restoration, and fusion.
- **⚙️ Intelligent Analysis of Medical Images:** Segmentation and diagnostic assistance.
- **⚙️ Metric Learning and Domain Generalization:** Contrastive learning, unsupervised and semi-supervised learning.
- **⚙️ Infrared Small Target Detection and Tracking:** Remote sensing and security scenarios.

# 🎓Leader Introduction

刘萍萍是吉林大学计算机科学与技术学院教授，博士生导师，中国计算机学会会员。研究方向为底层视觉图像增强，度量学习，医学影像分析，红外小目标检测及嵌入式人工智能。近三年在国际顶级会议/期刊（CCF-A/B/C，中科院 1 区/2 区）上发表学术论文21 篇，其中以第一/通讯作者身份发表论文 11 篇。 担任《吉林大学学报（工学版）》编委，长期担任 CCF 顶级会议 IJCAI，AAAI，NIPS，ACM MM 等和 IEEE 旗舰期刊 TIP，TCYB， TNNLS， ACM 旗舰期刊TMM, TKDD 等的审稿人。获得“2024年度中国商业联合会科技进步奖二等奖”一项（排名第一），“2024年度中国发明协会发明创新创业奖二等奖”一项（排名第三）。中国授权发明专利31项。承担国家自然科学基金、中国博士后基金、吉林省自然科学基金、吉林省青年科研基金、吉林省工业领域重点研发项目等多项科研项目

Liu Pingping is a Professor at the School of Computer Science and Technology, Jilin University, and a doctoral supervisor. She is a member of the China Computer Federation. Her research interests include low-level vision image enhancement, metric learning, medical image analysis, infrared small target detection, and embedded artificial intelligence.
In the past three years, she has published 21 academic papers in top international conferences/journals (CCF-A/B/C, Chinese Academy of Sciences Zones 1/2), with 11 of these papers as the first or corresponding author. She serves as an editorial board member for the Journal of Jilin University (Engineering Edition) and has been a reviewer for leading CCF conferences such as IJCAI, AAAI, NIPS, ACM MM, as well as for flagship IEEE journals including TIP, TCYB, TNNLS, and ACM flagship journals like TMM and TKDD.
She has received the "2024 China Association for Productivity Promotion Scientific and Technological Progress Award (Second Prize)" (ranked first) and the "2024 China Invention Association Innovation and Entrepreneurship Award (Second Prize)" (ranked third). Professor Liu holds 31 authorized patents in China.
She has undertaken multiple research projects, including those supported by the National Natural Science Foundation, the China Postdoctoral Fund, the Jilin Provincial Natural Science Fund, the Jilin Provincial Youth Science Fund, and key R&D projects in the industrial sector of Jilin Province.

# 🔥 News
- *2025.08*: &nbsp;🎉🎉 One paper accepted to TGRS 2025. 
- *2025.07*: &nbsp;🎉🎉 One paper accepted to ICCV 2025.
- *2025.06*: &nbsp;🎉🎉 Two paper accepted to ESWA 2025.
- *2025.05*: &nbsp;🎉🎉 One paper accepted to INFFUS 2025.
- *2025.03*: &nbsp;🎉🎉 One paper accepted to ICME 2025.
- *2024.07*: &nbsp;🎉🎉 One paper accepted to ACM MM 2024.

# 📚 Selected Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TGRS 2025</div><img src='images/tgrs2025.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[LSDSSMs:Infrared Small Target Detection Network based on Low-Rank Sparse Decomposition State Space Models](https://ieeexplore.ieee.org/document/11106451)

Yubing Lu, **Pingping Liu***, Aohua Li, Qiuzhan Zhou, Kai Zhang

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2025</div><img src='images/CWNet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CWNet: Causal Wavelet Network for Low-Light Image Enhancement](https://arxiv.org/abs/2507.10689)

Tongshun Zhang, **Pingping Liu***, Yubing Lu, Mengen Cai, Zijian Zhang, Zhe Zhang, Qiuzhan Zhou

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ESWA 2025</div><img src='images/eswa2025-1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Multi-modal fusion guided retinex-based low-light image enhancement](https://www.sciencedirect.com/science/article/pii/S0957417425022729?via%3Dihub)

**Pingping Liu***, Xiaoyi Wang, Tongshun Zhang, Liyuan Yin

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">INFFUS 2025</div><img src='images/inffus2025.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Cross-modal guided and refinement-enhanced Retinex network for robust low-light image enhancement](https://arxiv.org/abs/2507.10689)

Tongshun Zhang, **Pingping Liu***, Mengen Cai, Xiaoyi Wang, Qiuzhan Zhou

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2024</div><img src='images/mm2024.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DMFourLLIE: Dual-Stage and Multi-Branch Fourier Network for Low-Light Image Enhancement](https://arxiv.org/abs/2412.00683)

Tongshun Zhang, **Pingping Liu***, Ming Zhao, Haotian Lv

</div>
</div>

<!-- 

# 🎖 Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# 📖 Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# 💬 Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# 💻 Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.

-->
